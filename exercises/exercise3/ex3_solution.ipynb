{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3: The complex temporality of real world data\n",
    "\n",
    "In this exercise we consider the complex temporality of real world data. An advantage of real world data compared to other sources of data is its rapid availability after collection. Clinical notes are for instance often available in a clinical data warehouse one day after their editions. Yet this strong advantage comes at a cost: the **heterogeneity of data temporalities**.\n",
    "\n",
    "We consider hereafter a statistical design that considers only data collected in a timespan $[t_{start}, t_{end}]$ and we evaluate the impact of data temporality on the choice of $t_{start}$ and $t_{end}$. As underlined in the previous exercises, data that is available in a clinical data data warehouse has been collected in various clinical softwares. Each software may feature a specific temporality, leading to an important heterogeneity. Hereafter, we consider the two following characteristics of data temporality:\n",
    "- **data timeliness** refers to the time needed to integrate data in the clinical data warehouse after the occurrence of the event of interest. If $t_{extract}$ refers to the date of data extraction from the clinical data warehouse for a study, and $\\Delta t_{timeliness}$ refers to the duration separating events from the full availability of their related data in a clinical data warehouse, one should limit the timespan of a study to the period before $t_{end} = t_{extract} - \\Delta t_{timeliness}$\n",
    "- **software deployment** refers to the fact that data may be available in a medical unit only if its associated clinical software has been deployed and used in this medical unit at the date of interest. The heterogeneity due to the software deployment is not only a heterogeneity relatively to the categories of data, but also relatively to the medical units, as the deployment of a clinical software may be realized progressively in a hospital. If one knows for each medical unit $i$ and a data category $cat$ the date $t^{(0)}_{cat}(i)$ of the software deployment, one can restrict the study to medical units $i$ such that $t^{(0)}_{cat}(i)<t_{start}$. This restriction makes it possible to consider a stable source of data throughout the period of the study.\n",
    "\n",
    "We illustrate now these challenges on our illustrative use case. As in exercise 1, we consider only structured data which timeliness parameters are known. We moreover assume that $t_{start}$ is set to the January 1st, 2022 by the investigator and that this date cannot be modified due to methodological issues.\n",
    "\n",
    "We initialize the notebook by importing the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import altair as alt\n",
    "import datetime\n",
    "alt.data_transformers.enable('default', max_rows=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from viz import plot_primary_kaplan, plot_secondary_kaplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration\n",
    "\n",
    "A fake dataset that mimics data coming from a clinical information system is made available in the */data* folder of this exercise.\n",
    "<br>For this study, data has been extracted from the Clinical Data Warehouse on December 1st, 2025.\n",
    "<br>The same data than in exercice 1 is imported\n",
    "\n",
    "## 1.1 Data extracted from the Clinical Data Warehouse\n",
    "\n",
    "Open the following files using the `pandas.read_pickle()` function : \n",
    "  - *data/df_person.pkl* as `df_person`\n",
    "  - *data/df_visit.pkl* as `df_visit`\n",
    "  - *data/df_condition.pkl* as `df_cond`\n",
    "  - *data/df_med.pkl* as `df_med`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Patients\n",
    "df_person = pd.read_pickle('data/df_person.pkl')\n",
    "# Visits\n",
    "df_visit = pd.read_pickle('data/df_visit.pkl')\n",
    "# Diagnosis (condition)\n",
    "df_cond = pd.read_pickle('data/df_condition.pkl')\n",
    "# Medication\n",
    "df_med = pd.read_pickle('data/df_med.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 A priori knowledge on data timeliness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We moreover assume that we have an a priori knowledge of the timeliness parameter $\\Delta t_{timeliness}$ of each data category:\n",
    "- $\\Delta t_{timeliness}^{(person)} = 1$ days\n",
    "- $\\Delta t_{timeliness}^{(visit)} = 5$ days \n",
    "- $\\Delta t_{timeliness}^{(cond)} = 45$ days\n",
    "- $\\Delta t_{timeliness}^{(med)} = 5$ day\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploration and pre-processing of the dataset\n",
    "\n",
    "We consider that the data cleaning presented in the exercise 1 has already been realized on the dataset. We now focus on the temporality issue.\n",
    "\n",
    "## 2.1 Adapting the study design to data timeliness\n",
    "\n",
    "Let's first set the end value of the study's timespan, $t_{end}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reminder**: we assume data was extracted from the clinical data warehouse on t_{extract} = December 1, 2025.\n",
    "\n",
    "We should consider a sufficiently long delay $\\Delta t_{timeliness}$ between the extraction time and the end of the study in order to account for the timeliness of all the categories of data:\n",
    "\n",
    "$\\Delta t_{timeliness} = \\max \\big[\\Delta t_{timeliness}^{(person)}, \\Delta t_{timeliness}^{(visit)}, \\Delta t_{timeliness}^{(cond)}, \\Delta t_{timeliness}^{(med)} \\big]= 45$ days.\n",
    "\n",
    "We can consequently set the value of $t_{end}$ to $t_{extract} - \\Delta t_{timeliness}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_max = datetime.date(2025, 12, 1) - datetime.timedelta(days=45)\n",
    "\n",
    "df_visit_fix = df_visit.query('visit_start_datetime < @t_max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Adapting the study design to the temporality of softwares' deployment\n",
    "\n",
    "For the sake of simplicity, we consider hereafter that the clinical softwares used to collect patients' identities, visits administrative information and medical conditions have been deployed long before the beginning of our study $t_{start}$. We focus therefore on the correction of the variability induced by the progressive deployment of the software used to collect medication data. We moreover assume that this software has been deployed per hospital (*i.e.* there is one $t^{(0)}_{med}$ per hospital).\n",
    "\n",
    "Let us first install the *eds-temporal-variability* library to benefit from its methods. This library has been developed to facilitate the handling of the software deployment temporality when considering data of the Greater Paris University Hospitals' Clinical Data Warehouse. Don't hesitate to read the library's documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creation of a probe related to medicaton data**\n",
    "\n",
    "As explained in the library's documentation, EDS-TeVa is expecting to work with [Pandas](https://pandas.pydata.org/) or [Koalas](https://koalas.readthedocs.io/en/latest/) DataFrames.  We provide various connectors to facilitate data fetching, namely a **LocalData** connector which create a Data object based on a folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from edsteva.io import LocalData\n",
    "\n",
    "data = LocalData(folder=\"data\")\n",
    "print(data.available_tables)\n",
    "\n",
    "# Dataframes are attributes of the Data object:\n",
    "display(data.df_visit.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, ona may define a probe per hospital to measure the variation of data availability in the clinical data warehouse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from edsteva.probes import BaseProbe\n",
    "\n",
    "# Definition of a new Probe class\n",
    "class VisitWithMed(BaseProbe):\n",
    "    def __init__(\n",
    "        self,\n",
    "    ):\n",
    "        self._index = ['care_site_id']\n",
    "        self._metrics = [\"c\", \"n_visit\"]\n",
    "        super().__init__(\n",
    "            index=self._index,\n",
    "        )\n",
    "\n",
    "    def compute_process(self, data, **kwargs):\n",
    "        df_probe = data.df_visit.merge(data.df_med, on=\"visit_occurrence_id\", how='left')\n",
    "        df_probe['date'] = df_probe.visit_start_datetime.dt.strftime(\"%Y-%m\")\n",
    "        df_probe = (\n",
    "            df_probe.groupby(['care_site_id', 'date'])\n",
    "            .agg({'visit_occurrence_id': \"count\", \"drug_source_value\": \"count\"})\n",
    "            .rename(columns={'visit_occurrence_id': 'n_visit'})\n",
    "            .reset_index()\n",
    "            .assign(\n",
    "                c=lambda pp: pp['drug_source_value'] / pp['n_visit'],\n",
    "            )\n",
    "            .drop(columns=['drug_source_value'])\n",
    "        )\n",
    "        return df_probe\n",
    "\n",
    "visit_with_med = VisitWithMed()\n",
    "visit_with_med.compute(data=data)\n",
    "visit_with_med.predictor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estimation of $t^{(0)}_{med}$ for each hospital**\n",
    "\n",
    "We consider now a simple fitting procedure, available in the *eds-temporal-variability* library to estimate $t^{(0)}_{med}$ for each hospital using the previously defined probe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from edsteva.models.step_function import StepFunction\n",
    "\n",
    "model = StepFunction()\n",
    "model.fit(probe=visit_with_med)\n",
    "model.estimates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now visualize the estimates of the deployment dates for each hospital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from edsteva.viz.plots import probe_plot\n",
    "probe_plot(probe=visit_with_med, fitted_model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "For each care site, we can see a step-shaped data availability curve. The step is centered on a date that is probably the date of the software's deployment. Yet, data is also available before this date... this may be due for instance to the fact that some data collected in previous clinical softwares is imported in the new software when it is deployed. This imported data is of lower quality than data natively collected in the new software because old data is filtered before import using rules that are usually not available to researchers, thus inducing potential statistical biases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filter data in order to correct for the deployment bias**\n",
    "\n",
    "We now filter data to keep only data originating from hospitals where the medication software was deployed before the beginning date of our study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_start = datetime.date(2022, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "list_taboo_hospital = []\n",
    "for _, row in model.estimates.iterrows():\n",
    "    if row['t_0'].date() > t_start:\n",
    "        list_taboo_hospital.append(row['care_site_id'])\n",
    "print('Hospitals which data is discarded: {}'.format(list_taboo_hospital))\n",
    "df_visit_fix = df_visit.query('care_site_id not in @list_taboo_hospital')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We moreover filter visits that begin before $t_{start}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_visit_fix = df_visit_fix.query('visit_start_datetime >= @t_start')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Statistical analysis\n",
    "\n",
    "Now that we have pre-processed raw data to correct flawed or missing values and to define research-relevant variables, we can conduct the statistical analysis. We plot the Kaplan-Meier estimates of survival curves, and realize the log-rank tests. \n",
    "\n",
    "**Primary objective: are the drugs efficient on the total population?**\n",
    "\n",
    "**Remark**: the Kaplan-Meier plot functions admit as parameter the end date of the study `t_end`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_primary_kaplan(df_person, [(df_visit_fix, df_med, 'all population')], t_end_of_study=t_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are coherent with exercise 1.\n",
    "\n",
    "**Secondary objective: sub-population analysis**\n",
    "\n",
    "To reach our secondary objective, we now conduct the same statistical analysis on sub-populations that correspond to different sexes and ages to obtain a better insight on drugs efficiencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_secondary_kaplan(df_person, [(df_visit_fix, df_med, '')], t_max, drug_name=\"drugA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_secondary_kaplan(df_person, [(df_visit_fix, df_med, '')], t_max, drug_name=\"drugB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we have introduced some difficulties related to handling the temporality of real world data. Using a simple example, we have shown how data temporality may impact the study design and how temporality parameters may be automatically computed using ad-hoc scientific libraries.\n",
    "\n",
    "In a real clinical data warehouse, this issue is much more complex due to the strong heterogeneity of the clinical information system. Better understanding the dynamics of the clinical information system appears necessary to conduct some studies on real world data : the expertise of the IT department may be leveraged therefore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Takeaways\n",
    "\n",
    "- An important challenge regarding the analysis of real world data comes from the its **temporality**.\n",
    "- Data **timeliness** refers to the latency of data integration. It may be due to various effects all over the data collection and curation workflows.\n",
    "- Moreover the constant **evolution of the clinical information system** (deployments of new softwares, etc.) leads to an heterogeneous availability in time and space of data collected in a hospital. It therefore appears necessary to correct this **software deployment bias** in the study's design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. References\n",
    "\n",
    "- Weiskopf, N. G., et C. Weng. « Methods and Dimensions of Electronic Health Record Data Quality Assessment: Enabling Reuse for Clinical Research ». Journal of the American Medical Informatics Association 20, nᵒ 1 (1 janvier 2013): 144‑51. https://doi.org/10.1136/amiajnl-2011-000681.\n",
    "- Finlayson, Samuel G., Adarsh Subbaswamy, Karandeep Singh, John Bowers, Annabel Kupke, Jonathan Zittrain, Isaac S. Kohane, et Suchi Saria. « The Clinician and Dataset Shift in Artificial Intelligence ». New England Journal of Medicine 385, nᵒ 3 (15 juillet 2021): 283‑86. https://doi.org/10.1056/NEJMc2104626.\n",
    "- Sáez, Carlos, Alba Gutiérrez-Sacristán, Isaac Kohane, Juan M García-Gómez, et Paul Avillach. « EHRtemporalVariability: Delineating Temporal Data-Set Shifts in Electronic Health Records ». GigaScience 9, nᵒ 8 (1 août 2020): giaa079. https://doi.org/10.1093/gigascience/giaa079.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ffb0fb47ea8f733c001ba519ad88900dd17f4bfc9ebfd0d356a457e5cc19a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
