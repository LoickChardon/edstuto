{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2: Data linkage\n",
    "\n",
    "In this exercise we want to evaluate the impact of duplicated patients in a dataset (*i.e.*, a patient having two or more digital identities). To address this issue, linkage algorithms may be used to merge records related to the same patient. They are commonly divided in **deterministic linkage** algorithms and in **probabilistic linkage** algorithms. Whereas deterministic algorithms rely on simple rules to match identifiers, probabilistic algorithms compute a similarity metric between pairs of records. A table of deduplicated patient identifiers is provided for examples of these two algorithms. \n",
    "\n",
    "In this exercice, we will : \n",
    "1. Deduplicate the dataset by using a deterministic algorithm\n",
    "2. Deduplicate the dataset by using a probabilistic algorithm\n",
    "3. Compare the Kaplan-Meyer curves between these 2 groups and non deduplicated data from exercice 1.\n",
    "\n",
    "We initialize the notebook by importing the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization library\n",
    "import matplotlib.pyplot as plt\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "\n",
    "# Dates management\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration\n",
    "\n",
    "\n",
    "A fake dataset that mimics data coming from a clinical information system is made available in the */data* folder of this exercise.\n",
    "<br>For this study, data has been extracted from the Clinical Data Warehouse on December 1st, 2025.\n",
    "<br>The same data than in exercice 1 is imported\n",
    "\n",
    "## 1.1 Data extracted from the Clinical Data Warehouse\n",
    "\n",
    "Open the following files using the `pandas.read_pickle()` function : \n",
    "  - *data/df_person.pkl* as `df_person`\n",
    "  - *data/df_visit.pkl* as `df_visit`\n",
    "  - *data/df_condition.pkl* as `df_cond`\n",
    "  - *data/df_med.pkl* as `df_med`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Patients\n",
    "df_person = pd.read_pickle('data/df_person.pkl')\n",
    "\n",
    "# Visits\n",
    "df_visit = pd.read_pickle('data/df_visit.pkl')\n",
    "\n",
    "# Diagnosis (condition)\n",
    "df_cond = pd.read_pickle('data/df_condition.pkl')\n",
    "\n",
    "# Medication\n",
    "df_med = pd.read_pickle('data/df_med.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data provided by the deterministic deduplication algorithm\n",
    "\n",
    "The results of the **deterministic algorithm** are made available in the *df_dedup_det* dataframe.\n",
    "\n",
    "- Open the *data/df_dedup_deterministic.pkl* file as `df_dedup_det` using the `pandas.read_pickle()` function.\n",
    "- Explore the type of each feature of the df_dedup_det DataFrame with the `.info()` function.\n",
    "- Check out the first rows of the DataFrame using the `.head()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dedup_det = pd.read_pickle('data/df_dedup_deterministic.pkl')\n",
    "df_dedup_det.info()\n",
    "df_dedup_det.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> The dataframe `df_dedup_det` is composed of 2 columns :\n",
    "- *unique_person_id* : this id is the *real* id for the patient\n",
    "- *person_id* : this id is another one, created by mistake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data provided by the probabilistic deduplication algorithm\n",
    "\n",
    "The results of the **probabilistic algorithm** are made available in the *df_dedup_proba* dataframe.\n",
    "\n",
    "- Open the *data/df_dedup_proba.pkl* file as `df_dedup_proba` using the `pandas.read_pickle()` function.\n",
    "- Explore the type of each feature of the df_dedup_proba DataFrame with the `.info()` function.\n",
    "- Check out the first rows of the DataFrame using the `.head()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dedup_proba = pd.read_pickle('data/df_dedup_proba.pkl')\n",
    "df_dedup_proba.info()\n",
    "df_dedup_proba.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> The dataframe `df_dedup_proba` is composed of 3 columns :\n",
    "- *unique_person_id* : this id is the *real* id for the patient\n",
    "- *person_id* : this id is another one, created by mistake\n",
    "- *prob* : the probability that the 2 these 2 ids are actually the same person"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Preprocessing\n",
    "\n",
    "## 2.1 Deduplicating using the deterministic algorithm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> The dataframe `df_dedup_det` is composed of 2 columns :\n",
    "- *unique_person_id* : this id is the *real* id for the patient\n",
    "- *person_id* : this id is another one, created by mistake\n",
    "\n",
    "We are going to clean the `df_person` dataframe by only keeping a single id per patient.\n",
    "- Create a dataframe `df_person_dedup_det` from `df_person` that contains 1 row per patient.\n",
    "\n",
    "TIPS : \n",
    "- Outer join `df_person` and `df_dedup_det` on *person_id* using the `pandas.merge()` function (see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html))\n",
    "- Fill in the *unique_person_id* column with the *person_id* column when empty using the `pandas.fillna()` function (see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html))\n",
    "- If several rows have the same *unique_person_id*, only keep the first one using `pandas.drop_duplicates()` (see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Outer Join\n",
    "df_person_dedup_det = pd.merge(df_person, df_dedup_det, on = 'person_id', how = 'outer')\n",
    "\n",
    "# Complete the unique_person_id column\n",
    "df_person_dedup_det['unique_person_id'] = df_person_dedup_det['unique_person_id'].fillna(df_person_dedup_det['person_id'])\n",
    "\n",
    "# Only keep one row per patient\n",
    "df_person_dedup_det = df_person_dedup_det.drop_duplicates(['unique_person_id'], keep = 'first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many patients have we left ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"We have {df_person_dedup_det.unique_person_id.nunique()} unique patient ids in this dataset when using the determinist algorithm.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Deduplicatng using probabilistic algorithm\n",
    "\n",
    "<br> The dataframe `df_dedup_proba` is composed of 3 columns :\n",
    "- *unique_person_id* : this id is the *real* id for the patient\n",
    "- *person_id* : this id is another one, created by mistake\n",
    "- *prob* : the probability that the 2 these 2 ids are actually the same person\n",
    "\n",
    "Observe the distribution of the probabilities using `pandas.describe()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dedup_proba['prob'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the estimated density of the distribution of the probabilities using `pandas.plot.density()` (see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.density.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_dedup_proba['prob'].plot.density()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is there a peak at probability = 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correction** :\n",
    "<br>The algorithm matches correctly all the patients that were matched in the deterministic algorithm.\n",
    "<br>The peak is the result of the patient for whom we are sure the match is correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function `deduplicate_proba(df_person: pd.DataFrame, df_dedup_proba: pd.DataFrame, score: int)` that returns a dataset of deduplicated person ids if their similarity score was above `score`.\n",
    "\n",
    "TIPS : \n",
    "- Create a subset dataframe `df_dedup_proba_score` of df_person_dedup_proba keeping only rows where `'prob' > score`\n",
    "- Outer join `df_person` and `df_dedup_proba_score` on *person_id* using the `pandas.merge()` function (see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.merge.html))\n",
    "- Fill in the *unique_person_id* column with the *person_id* column when empty using the `pandas.fillna()` function (see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.fillna.html))\n",
    "- If several rows have the same *unique_person_id*, only keep the first one using `pandas.drop_duplicates()` (see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def deduplicate_proba(df_person: pd.DataFrame, df_dedup_proba: pd.DataFrame, score: int):\n",
    "    #Only keep rows with a probability above the value score\n",
    "    df_dedup_proba_score = df_dedup_proba[df_dedup_proba['prob'] > score]\n",
    "    # Outer Join\n",
    "    df_person_dedup_proba  = pd.merge(df_person, df_dedup_proba_score, on = 'person_id', how = 'outer')\n",
    "    # Only unique ids in unique_person_id\n",
    "    df_person_dedup_proba['unique_person_id'] = df_person_dedup_proba['unique_person_id'].fillna(df_person_dedup_proba['person_id'])\n",
    "    # Only keep one row per patient\n",
    "    df_person_dedup_proba = df_person_dedup_proba.drop_duplicates(['unique_person_id'], keep = 'first')\n",
    "    return df_person_dedup_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe `df_person_dedup_proba_90` that only keeps the similarity scores above 0.90.<br>\n",
    "How many patients do we have if the similarity score must be above 0.90 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_person_dedup_proba_90 = deduplicate_proba(df_person, df_dedup_proba, score=0.90)\n",
    "print(f\"We have {df_person_dedup_proba_90.unique_person_id.nunique()} unique patient ids in this dataset when using the probabilistic algorithm and a threshold of 0.90.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe `df_person_dedup_proba_20` that only keeps the similarity scores above 0.20.<br>\n",
    "How many patients do we have if the similarity score must be above 0.20 ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_person_dedup_proba_20 = deduplicate_proba(df_person, df_dedup_proba, score = 0.20)\n",
    "print(f\"We have {df_person_dedup_proba_20.unique_person_id.nunique()} unique patient ids in this dataset when using the probabilistic algorithm and a threshold of 0.20.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that most linked records feature a high similarity score, but a significant amount of additional records would be matched by setting a low threshold. Let's compare two strategies for threshold setting, a high threshold strategy (*i.e.* keeping only high-confidence linkages, but missing some records that should be matched) and a low threshold strategy (*i.e.* linking most records that feature some similarities, among which some linkages correspond actually to different visits). \n",
    "<br>We choose as thresholds the values **0.9** and **0.2** to compare the consequences of both thresholds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Statistical analysis\n",
    "\n",
    "Now that we have deduplicated patient ids,  we can conduct the statistical analysis showing the impact of the deduplication process. \n",
    "<br>We plot the Kaplan-Meier estimates of survival curves, and realize the log-rank tests.\n",
    "<br> The same functions `plot_primary_kaplan` used in the previous notebook can be used to plot the curves.\n",
    "<br> If needed, you can print the docstrings using `print(plot_primary_kaplan.__doc__)`.\n",
    "\n",
    "For this exercise, we have only kept the visits regarding the epidemic conditions. `df_visit` and `df_med` can be used to without any preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_end_of_study = datetime.date(2025,12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    " #Import the helper functions\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from viz import plot_primary_kaplan, plot_secondary_kaplan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(plot_primary_kaplan.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Without deduplicating the person dataset\n",
    "\n",
    "Plot the  primary Kaplan-Meier estimates for the whole `df_person` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_primary_kaplan(\n",
    "    df_person,\n",
    "    [(df_visit, df_med, 'No deduplication')],\n",
    "    t_end_of_study\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be concluded on the effect of each drugs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correction** :\n",
    "<br> It seems that both drugs have a positive impact on the survival of the patients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Using the determinist deduplication\n",
    "\n",
    "Plot the  primary Kaplan-Meier estimates for the whole `df_person_dedup_det` dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_primary_kaplan(\n",
    "    df_person_dedup_det,\n",
    "    [(df_visit, df_med, '')],\n",
    "    t_end_of_study\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be concluded on the effect of each drugs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correction** :\n",
    "<br> It seems that both drugs have a positive impact on the survival of the patients\n",
    "<br> However, the effect of drug B seems to be more moderated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Using the probabilistic deduplication\n",
    "\n",
    "Plot the  primary Kaplan-Meier estimates for the whole `df_person_dedup_proba_90` dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_primary_kaplan(\n",
    "    df_person_dedup_proba_90, \n",
    "    [(df_visit, df_med, '')], \n",
    "    t_end_of_study\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be concluded on the effect of each drugs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correction** :\n",
    "<br> It seems that both drugs have a positive impact on the survival of the patients\n",
    "<br> However, the effect of drug B seems to be even more moderated. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the  primary Kaplan-Meier estimates for the whole `df_person_dedup_proba_20` dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_primary_kaplan(\n",
    "    df_person_dedup_proba_20, \n",
    "    # df_cond, \n",
    "    [(df_visit, df_med, '')], \n",
    "    t_end_of_study\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The survival curves obtained with the low value threshold diverge strongly from the high value threshold or from the survival curves computed using the deterministic algorithm. Our confidence in the low value threshold is therefore low, but we should keep investigating this issue, for instance realizing a validation of the probabilistic linkage by a chart review campaign.\n",
    "\n",
    "In this exercise, we have shown some challenges related to the linkage of records in a clinical data warehouse. Various strategies may be adopted, and this methodological choice once more impacts the final results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Takeaways\n",
    "\n",
    "- Clinical data warehouses contain **data collected in various clinical softwares** that may not always share **common identifiers**.\n",
    "- It appears necessary to **link data coming from different softwares** prior to they statistical analysis (linkage to a common identity, to a visit occurrence, etc.). Linkage may rely on common identifiers or on more involved linkage algorithms.\n",
    "- Linkage algorithms are commonly divided in **deterministic linkage** algorithms and in **probabilistic linkage** algorithms. Whereas deterministic algorithms rely on simple rules to match identifiers, probabilistic algorithms compute a similarity metric between pairs of records.\n",
    "- Methodological choices related to data linkage may impact the result of the overall analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. References\n",
    "\n",
    "- Harron, Katie, Harvey Goldstein, et Chris Dibben. Methodological Developments in Data Linkage. Wiley Series in Probability and Statistics. Wiley, 2016.\n",
    "- Harron, Katie, Angie Wade, Ruth Gilbert, Berit Muller-Pebody, et Harvey Goldstein. « Evaluating Bias Due to Data Linkage Error in Electronic Healthcare Records ». BMC Medical Research Methodology 14, nᵒ 1 (décembre 2014): 36. https://doi.org/10.1186/1471-2288-14-36.\n",
    "- Gilbert, Ruth, Rosemary Lafferty, Gareth Hagger-Johnson, Katie Harron, Li-Chun Zhang, Peter Smith, Chris Dibben, et Harvey Goldstein. « GUILD: GUidance for Information about Linking Data Sets† ». Journal of Public Health 40, nᵒ 1 (1 mars 2018): 191‑98. https://doi.org/10.1093/pubmed/fdx037.\n",
    "- Vatsalan, Dinusha, Peter Christen, et Vassilios S. Verykios. « A Taxonomy of Privacy-Preserving Record Linkage Techniques ». Information Systems 38, nᵒ 6 (septembre 2013): 946‑69. https://doi.org/10.1016/j.is.2012.11.005."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ffb0fb47ea8f733c001ba519ad88900dd17f4bfc9ebfd0d356a457e5cc19a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
