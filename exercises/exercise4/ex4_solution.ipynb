{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4: Clinical notes and natural language processing\n",
    "\n",
    "\n",
    "In this exercice we introduce an important new category of data, **clinical notes**, along with **eds-nlp** (see [doc](https://aphp.github.io/edsnlp)) a scientific library that facilitates the definition of NLP algorithms for French clinical texts.\n",
    "\n",
    "The use case consists of validating/completing the drug table. Indeed, we fear that natively structured data on drugs are incomplete leading to patients being falsely included in the control cohort although they had a drug administred. We make the assumption that textual data contained in clinical notes are complete as it is well known that care professionals extensively use this format to record information. \n",
    "\n",
    "In this exercice, we will : \n",
    "1. Find drug administration for patients using NLP methods\n",
    "2. Compare the Kaplan Meyer curves obtained using or not NLP algorithms to identify drugs.\n",
    "\n",
    "We initialize the notebook by importing the following libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization library\n",
    "import altair as alt\n",
    "alt.data_transformers.enable('default', max_rows=None)\n",
    "\n",
    "# Dates management\n",
    "import datetime\n",
    "\n",
    "# For the computation of Kaplan-Meier estimates and log-rank tests\n",
    "import lifelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Table of content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Data Exploration\n",
    "\n",
    "A fake dataset that mimics data coming from a clinical information system is made available in the */data* folder of this exercise.\n",
    "<br>For this study, data has been extracted from the Clinical Data Warehouse on December 1st, 2025.\n",
    "<br>The same data than in exercice 1 is imported\n",
    "\n",
    "## 1.1 Data extracted from the Clinical Data Warehouse\n",
    "\n",
    "Open the following files using the `pandas.read_pickle()` function : \n",
    "  - *data/df_person.pkl* as `df_person`\n",
    "  - *data/df_visit.pkl* as `df_visit`\n",
    "  - *data/df_condition.pkl* as `df_cond`\n",
    "  - *data/df_med.pkl* as `df_med`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Patients\n",
    "df_person = pd.read_pickle('data/df_person.pkl')\n",
    "# Visits\n",
    "df_visit = pd.read_pickle('data/df_visit.pkl')\n",
    "# Diagnosis (condition)\n",
    "df_cond = pd.read_pickle('data/df_condition.pkl')\n",
    "# Medication\n",
    "df_med = pd.read_pickle('data/df_med.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dataframe `df_visit_med` that indicates which drug was administered for each visit. \n",
    "\n",
    "TIP : LEFT JOIN `df_visit` and `df_med` on `visit_occurrence_id` using the `pandas.merge()` function (see [doc](https://pandas.pydata.org/docs/reference/api/pandas.merge.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_visit_med = pd.merge(df_visit, df_med, on = 'visit_occurrence_id', how = 'left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many patients are in the study?\n",
    "<br>We suppose deduplication has already been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f\"We have {df_person.person_id.nunique()} unique patient ids in this dataset.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure every patient only has only one visit and therefore one drug administration\n",
    "\n",
    "TIPS : Count the number of patients in the dataset `df_visit_med` using `pandas.value_counts()` and check there is only one occurence of every patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_value_count = df_visit_med.person_id.value_counts()\n",
    "n_numerous = df_value_count[df_value_count > 1].size\n",
    "print(\"{} patients have more than one visit\".format(n_numerous))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many patients have had : \n",
    "- drugA  administered ?\n",
    "- drugB administered ?\n",
    "\n",
    "TIP : Count the number of drugA and drugB administered in the dataset `df_visit_med` using `pandas.value_counts()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "count_drug = df_med.drug_source_value.value_counts()\n",
    "print(f\" {count_drug['drugA']} patients have had the drugA administered. \\n{count_drug['drugB']} patients have had the drugB administered.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many patients have had no drug administered according to the structured information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_person.person_id.nunique() - len(df_med)\n",
    "\n",
    "print(f\"{df_person.person_id.nunique() - count_drug['drugA'] - count_drug['drugA']} patients have had no drugs administerd.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Clinical Notes\n",
    "\n",
    "In this exercise we introduce two new categories of data:\n",
    "- **free text** contained in clinical notes (*i.e.* raw data)\n",
    "- variables that have been **extracted by a pre-defined NLP algorithm** (*i.e.* extracted data).\n",
    "\n",
    "Free text is made available in a *df_note* dataframe\n",
    "\n",
    "- Open the *data/df_note.pkl* file as `df_note` using the pandas.read_pickle() function.\n",
    "- Explore the type of each feature of the df_note DataFrame with the .info() function.\n",
    "- Check out the first rows of the DataFrame using the .head() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_note = pd.read_pickle('data/df_note.pkl')\n",
    "df_note.info()\n",
    "df_note.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`df_note` is composed of 5 columns :\n",
    "- *visit_occurrence_id* : identifier of the visit\n",
    "- *note_id* : identifier of the medical note\n",
    "- *note_text* : free text contained in the medical note\n",
    "- *note_datetime* : date of text edition\n",
    "- *cdm_source* : name of the clinical software\n",
    "\n",
    "Print an example of a note using the funciton `pandas.sample()`\n",
    "\n",
    "TIP : Use the function `pandas.sample()`(see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html)) and the function `pandas.squeeze()`(see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.squeeze.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df_note.sample(1)['note_text'].squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. First steps with natural language processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a new rule-based NLP algorithm that extracts drugs mentioned in clinical notes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a rule-based algorithm that consists in looking for mentions of drugs in the texts and in discarding false positive detections by predicting modifiers (negation, etc.).\n",
    "\n",
    "**Step 1: Definition of the vocabularies**\n",
    "\n",
    "We start by asking clinicians to consolidate a list of synonyms used to report the usage of drug A or drug B in the clinical notes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clinicians indicated that the following synonyms could be used\n",
    "\n",
    "terms = dict(\n",
    "    drugA=['drugA', 'pneumo-drug', 'SpinA'],\n",
    "    drugB=['drugB', 'noso-plat', 'testmedB'],\n",
    "    medicament=['médicament', 'médicamenteux']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Definition of a natural language processing pipeline (rule-based)**\n",
    "\n",
    "The documentation for the NLP librairie is available [here](https://aphp.github.io/edsnlp)\n",
    "\n",
    "We now integrate this dictionary in a NLP-pipeline as described in the *eds-nlp* documentation, in order to realize the various pre-processing steps necessary to extract a meaningful variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Utiliser edsnlp pour extraitre les 3 entités ci dessus : \n",
    "import spacy\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Load declared pipelines\n",
    "# from edsnlp import components\n",
    "from edsnlp.processing.parallel import pipe as parallel_pipe\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a first pipeline using :\n",
    "- eds.sentences \n",
    "- eds.normalier\n",
    "- eds.matcher with `terms` as the configuration file\n",
    "- eds.negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"fr\")\n",
    "# sentencizer component\n",
    "nlp.add_pipe('eds.sentences')\n",
    "nlp.add_pipe(\"eds.normalizer\")\n",
    "# Matcher component\n",
    "nlp.add_pipe(\"eds.matcher\", config=dict(terms=terms))\n",
    "nlp.add_pipe(\"eds.negation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the pipeline to one document to see if it works (see [doc](https://aphp.github.io/edsnlp/latest/tutorials/matching-a-terminology/#visualising-matched-entities)).\n",
    "\n",
    "TIPS : \n",
    "- Use the function `pandas.sample()`(see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html)) and the function `pandas.squeeze()`(see [doc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.squeeze.html)) to extract a text.\n",
    "- Apply your nlp pipeline to create a `doc`\n",
    "- Apply `displacy.render()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "text = df_note.sample(1)['note_text'].squeeze()\n",
    "\n",
    "# Process your text in one call !\n",
    "doc = nlp(text)\n",
    "\n",
    "colors = {\n",
    "    \"drugA\": \"orange\",\n",
    "    \"drugB\": \"steelblue\",\n",
    "    \"medicament\" : \"green\"\n",
    "}\n",
    "options = {\n",
    "    \"colors\": colors,\n",
    "}\n",
    "\n",
    "displacy.render(doc, style=\"ent\", options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Application of the natural language processing pipeline on all the clinical notes**\n",
    "\n",
    "Apply this NLP pipeline to the texts of our dataset to extract entities by using the `edsnlp.parallel_pipe()` function (see [doc](https://aphp.github.io/edsnlp/latest/tutorials/multiple-texts/#processing-a-pandas-dataframe)).\n",
    "<br>You should obtain a `pd.DataFrame` *ents*\n",
    "\n",
    "A `pick_result` function is given to standardise the output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pick_results(doc):\n",
    "    \"\"\"\n",
    "    This function provides the entities that must be collected by the nlp process.\n",
    "    \"\"\"\n",
    "    return [{\n",
    "             'note_id':e.doc._.note_id,\n",
    "             'visit_occurrence_id':e.doc._.visit_occurrence_id,\n",
    "             'lexical_variant':e.text,\n",
    "             'label':e.label_,\n",
    "             'negation':e._.negation\n",
    "             } \n",
    "             for e in doc.ents if doc.ents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ents = parallel_pipe(\n",
    "                df_note,\n",
    "                nlp,\n",
    "                context=['note_id', 'visit_occurrence_id'],\n",
    "                progress_bar=False,\n",
    "                n_jobs=-2, \n",
    "                results_extractor = pick_results,\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the first rows of the dataframe `ents`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Create rules to classify each result and identify the patients for each drug**\n",
    "\n",
    "First, we classify each entity detected according to the rules bellow : \n",
    "\n",
    "- (drugA OR drugB OR medicament) AND NEGATION = control\n",
    "- drugA AND NOT(NEGATION) = cohortA\n",
    "- drugB AND NOT(NEGATION) = cohortB\n",
    "- else : unknown\n",
    "  \n",
    "Then, for a given `note_id` aka a given `visit_occurrence_id`, we combine the entities detected and classified as followed : \n",
    "- if control + cohortA = ambiguous\n",
    "- if control + cohortB = ambiguous\n",
    "- if cohortA + cohortB = ambiguous\n",
    "- if control + unknown = control\n",
    "- if cohortA + unknown = cohortA\n",
    "- if cohortB + unknown = cohortB\n",
    "\n",
    "The classification function `calc_value` is provided. <br>\n",
    "The processed data extracted from clinical notes is avaible in a `pd.DataFrame`*ents_grouped*.\n",
    "\n",
    "`ents_grouped` is composed of 2 columns :\n",
    "- *visit_occurrence_id* : identifier of the visit\n",
    "- *drug_source_value* : The output of the NLP° and the classification algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calc_value(x):\n",
    "    state = \"unknown\"\n",
    "    for _, row in x.iterrows():\n",
    "        if row['label'] in ['medicament', 'drugA', 'drugB'] and row['negation']:\n",
    "            if state == \"unknown\" or state == \"control\":\n",
    "                state = \"control\"\n",
    "            else:\n",
    "                state = \"ambiguous\"\n",
    "        elif row['label'] == 'drugA' and not row['negation']:\n",
    "            if state == \"unknown\" or state == \"drugA\":\n",
    "                state = \"drugA\"\n",
    "            else:\n",
    "                state = \"ambiguous\"\n",
    "        elif row['label'] == 'drugB' and not row['negation']:\n",
    "            if state == \"unknown\" or state == \"drugB\":\n",
    "                state = \"drugB\"\n",
    "            else:\n",
    "                state = \"ambiguous\"\n",
    "    return state\n",
    "\n",
    "undesired_state = ['unknown', 'ambiguous']\n",
    "ents_grouped = ents.groupby('visit_occurrence_id').apply(calc_value).to_frame('drug_source_value').reset_index()\n",
    "ents_grouped.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Compare nlp results to structured data provided by the hospitals**\n",
    "\n",
    "\n",
    "Acccording to the NLP-pipeline, how many patients have had the drug : \n",
    "- drugA  administered ?\n",
    "- drugB administered ?\n",
    "\n",
    "TIP : Count the number of drugA and drugB administered in the dataset `ents_grouped` using `pandas.value_counts()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ents_grouped.drug_source_value.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Statistical analysis\n",
    "\n",
    "Now that we have identified drug admission using NLP,  we can conduct the statistical analysis showing the impact of the missing data . \n",
    "<br>We plot the Kaplan-Meier estimates of survival curves, and realize the log-rank tests.\n",
    "<br> The same functions `plot_primary_kaplan` used in the previous notebook can be used to plot the curves.\n",
    "<br> If needed, you can print the docstrings using `print(plot_primary_kaplan.__doc__)`.\n",
    "\n",
    "In this exercice, we have only kept the visits regarding the epidemic conditions. `df_visit` and `df_med` can be used to without any preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "t_end_of_study = datetime.date(2025,12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import the helper functions\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from viz import plot_primary_kaplan, plot_secondary_kaplan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Without NLP extraction algorithm the person dataset\n",
    "\n",
    "Plot the  primary Kaplan-Meier estimates for the whole `df_person` DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_primary_kaplan(df_person, [(df_visit, df_med, 'all population')], t_end_of_study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can be concluded on the effect of each drugs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correction** :\n",
    "<br> It seems that drugA has a positive impact on the survival of the patients.\n",
    "<br> but that drugB doesn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Using the NLP extraction algorithm\n",
    "\n",
    "Plot the  primary Kaplan-Meier estimates for the whole `ents_grouped` dataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plot_primary_kaplan(df_person, [(df_visit, ents_grouped, 'all population')], t_end_of_study)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we have illustrated some challenges related to handling clinical notes when conducting a study using real-world data. We have shown that different approaches may be adopted and compared."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Takeaways\n",
    "\n",
    "- **Clinical notes** are unstructured data that contain numerous pieces of information but that are challenging to analyze. Specific pre-processing pipelines should be developed, validated and deployed to extract structured variables out of unstructured texts (**Natural Language Processing** algorithms - NLP).\n",
    "- Natural Language processing algorithms rely either on a **rule-based approach** or on a **machine learning approach**. Here we implemented only the rule-based approach, which is technically simpler than machine learning approaches, but require a strong contribution from expert clinicians to handcraft rules. Both approaches have their pros and cons and they may be compared on some specific tasks.\n",
    "- A single variable used at the statistical analysis stage may be **defined leveraging various sources of data**, either structured or unstructured. The methodology used to define each variable may impact the result of the statistical analysis, and it should consequently be discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. References\n",
    "\n",
    "- Honnibal, Matthew, Ines Montani, Matthew Honnibal, Henning Peters, Sofie Van Landeghem, Maxim Samsonov, Jim Geovedi, et al. explosion/spaCy: v2.1.7: Improved evaluation, better language factories and bug fixes. Zenodo, 2019. https://doi.org/10.5281/zenodo.3358113.\n",
    "- Aronow, D. B., F. Fangfang, et W. B. Croft. « Ad Hoc Classification of Radiology Reports ». Journal of the American Medical Informatics Association 6, nᵒ 5 (1 septembre 1999): 393‑411. https://doi.org/10.1136/jamia.1999.0060393.\n",
    "- Garcelon, Nicolas, Antoine Neuraz, Vincent Benoit, Rémi Salomon, et Anita Burgun. « Improving a Full-Text Search Engine: The Importance of Negation Detection and Family History Context to Identify Cases in a Biomedical Data Warehouse ». Journal of the American Medical Informatics Association, 20 octobre 2016, ocw144. https://doi.org/10.1093/jamia/ocw144.\n",
    "- Jouffroy, Jordan, Sarah F Feldman, Ivan Lerner, Bastien Rance, Anita Burgun, et Antoine Neuraz. « Hybrid Deep Learning for Medication-Related Information Extraction From Clinical Texts in French: MedExt Algorithm Development Study ». JMIR Medical Informatics 9, nᵒ 3 (16 mars 2021): e17934. https://doi.org/10.2196/17934.\n",
    "- Névéol, Aurélie, Hercules Dalianis, Sumithra Velupillai, Guergana Savova, et Pierre Zweigenbaum. « Clinical Natural Language Processing in Languages Other than English: Opportunities and Challenges ». Journal of Biomedical Semantics 9, nᵒ 1 (décembre 2018): 12. https://doi.org/10.1186/s13326-018-0179-8."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2ffb0fb47ea8f733c001ba519ad88900dd17f4bfc9ebfd0d356a457e5cc19a15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
